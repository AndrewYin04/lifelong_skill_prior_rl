{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['data']>\n",
      "<KeysViewHDF5 ['demo_0', 'demo_1', 'demo_10', 'demo_11', 'demo_12', 'demo_13', 'demo_14', 'demo_15', 'demo_16', 'demo_17', 'demo_18', 'demo_19', 'demo_2', 'demo_20', 'demo_21', 'demo_22', 'demo_23', 'demo_24', 'demo_25', 'demo_26', 'demo_27', 'demo_28', 'demo_29', 'demo_3', 'demo_30', 'demo_31', 'demo_32', 'demo_33', 'demo_34', 'demo_35', 'demo_36', 'demo_37', 'demo_38', 'demo_39', 'demo_4', 'demo_40', 'demo_41', 'demo_42', 'demo_43', 'demo_44', 'demo_45', 'demo_46', 'demo_47', 'demo_48', 'demo_49', 'demo_5', 'demo_6', 'demo_7', 'demo_8', 'demo_9']>\n",
      "demo_0\n",
      "<HDF5 dataset \"actions\": shape (234, 7), type \"<f8\">\n",
      "demo_1\n",
      "<HDF5 dataset \"actions\": shape (187, 7), type \"<f8\">\n",
      "demo_10\n",
      "<HDF5 dataset \"actions\": shape (176, 7), type \"<f8\">\n",
      "demo_11\n",
      "<HDF5 dataset \"actions\": shape (200, 7), type \"<f8\">\n",
      "demo_12\n",
      "<HDF5 dataset \"actions\": shape (169, 7), type \"<f8\">\n",
      "demo_13\n",
      "<HDF5 dataset \"actions\": shape (202, 7), type \"<f8\">\n",
      "demo_14\n",
      "<HDF5 dataset \"actions\": shape (223, 7), type \"<f8\">\n",
      "demo_15\n",
      "<HDF5 dataset \"actions\": shape (234, 7), type \"<f8\">\n",
      "demo_16\n",
      "<HDF5 dataset \"actions\": shape (211, 7), type \"<f8\">\n",
      "demo_17\n",
      "<HDF5 dataset \"actions\": shape (167, 7), type \"<f8\">\n",
      "demo_18\n",
      "<HDF5 dataset \"actions\": shape (197, 7), type \"<f8\">\n",
      "demo_19\n",
      "<HDF5 dataset \"actions\": shape (165, 7), type \"<f8\">\n",
      "demo_2\n",
      "<HDF5 dataset \"actions\": shape (180, 7), type \"<f8\">\n",
      "demo_20\n",
      "<HDF5 dataset \"actions\": shape (186, 7), type \"<f8\">\n",
      "demo_21\n",
      "<HDF5 dataset \"actions\": shape (182, 7), type \"<f8\">\n",
      "demo_22\n",
      "<HDF5 dataset \"actions\": shape (181, 7), type \"<f8\">\n",
      "demo_23\n",
      "<HDF5 dataset \"actions\": shape (199, 7), type \"<f8\">\n",
      "demo_24\n",
      "<HDF5 dataset \"actions\": shape (172, 7), type \"<f8\">\n",
      "demo_25\n",
      "<HDF5 dataset \"actions\": shape (167, 7), type \"<f8\">\n",
      "demo_26\n",
      "<HDF5 dataset \"actions\": shape (190, 7), type \"<f8\">\n",
      "demo_27\n",
      "<HDF5 dataset \"actions\": shape (196, 7), type \"<f8\">\n",
      "demo_28\n",
      "<HDF5 dataset \"actions\": shape (180, 7), type \"<f8\">\n",
      "demo_29\n",
      "<HDF5 dataset \"actions\": shape (184, 7), type \"<f8\">\n",
      "demo_3\n",
      "<HDF5 dataset \"actions\": shape (185, 7), type \"<f8\">\n",
      "demo_30\n",
      "<HDF5 dataset \"actions\": shape (187, 7), type \"<f8\">\n",
      "demo_31\n",
      "<HDF5 dataset \"actions\": shape (194, 7), type \"<f8\">\n",
      "demo_32\n",
      "<HDF5 dataset \"actions\": shape (259, 7), type \"<f8\">\n",
      "demo_33\n",
      "<HDF5 dataset \"actions\": shape (172, 7), type \"<f8\">\n",
      "demo_34\n",
      "<HDF5 dataset \"actions\": shape (178, 7), type \"<f8\">\n",
      "demo_35\n",
      "<HDF5 dataset \"actions\": shape (189, 7), type \"<f8\">\n",
      "demo_36\n",
      "<HDF5 dataset \"actions\": shape (200, 7), type \"<f8\">\n",
      "demo_37\n",
      "<HDF5 dataset \"actions\": shape (195, 7), type \"<f8\">\n",
      "demo_38\n",
      "<HDF5 dataset \"actions\": shape (173, 7), type \"<f8\">\n",
      "demo_39\n",
      "<HDF5 dataset \"actions\": shape (208, 7), type \"<f8\">\n",
      "demo_4\n",
      "<HDF5 dataset \"actions\": shape (170, 7), type \"<f8\">\n",
      "demo_40\n",
      "<HDF5 dataset \"actions\": shape (150, 7), type \"<f8\">\n",
      "demo_41\n",
      "<HDF5 dataset \"actions\": shape (169, 7), type \"<f8\">\n",
      "demo_42\n",
      "<HDF5 dataset \"actions\": shape (190, 7), type \"<f8\">\n",
      "demo_43\n",
      "<HDF5 dataset \"actions\": shape (244, 7), type \"<f8\">\n",
      "demo_44\n",
      "<HDF5 dataset \"actions\": shape (174, 7), type \"<f8\">\n",
      "demo_45\n",
      "<HDF5 dataset \"actions\": shape (196, 7), type \"<f8\">\n",
      "demo_46\n",
      "<HDF5 dataset \"actions\": shape (167, 7), type \"<f8\">\n",
      "demo_47\n",
      "<HDF5 dataset \"actions\": shape (165, 7), type \"<f8\">\n",
      "demo_48\n",
      "<HDF5 dataset \"actions\": shape (199, 7), type \"<f8\">\n",
      "demo_49\n",
      "<HDF5 dataset \"actions\": shape (184, 7), type \"<f8\">\n",
      "demo_5\n",
      "<HDF5 dataset \"actions\": shape (173, 7), type \"<f8\">\n",
      "demo_6\n",
      "<HDF5 dataset \"actions\": shape (189, 7), type \"<f8\">\n",
      "demo_7\n",
      "<HDF5 dataset \"actions\": shape (200, 7), type \"<f8\">\n",
      "demo_8\n",
      "<HDF5 dataset \"actions\": shape (216, 7), type \"<f8\">\n",
      "demo_9\n",
      "<HDF5 dataset \"actions\": shape (162, 7), type \"<f8\">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_463534/1192151577.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  actions_np = np.array(actions)\n"
     ]
    }
   ],
   "source": [
    "actions = []\n",
    "dones = []\n",
    "obs = []\n",
    "rewards = []\n",
    "robot_states = []\n",
    "states = []\n",
    "\n",
    "with h5py.File(\"libero/datasets/libero_10/STUDY_SCENE1_pick_up_the_book_and_place_it_in_the_back_compartment_of_the_caddy_demo.hdf5\", \"r\") as file:\n",
    "    data_group = file['data']\n",
    "    print(file.keys())\n",
    "    print(data_group.keys())\n",
    "    for sample in data_group.keys():\n",
    "        print(sample)\n",
    "        curr_sample = data_group[sample]\n",
    "        # print(curr_sample.keys())\n",
    "        curr_sample[\"actions\"][:]\n",
    "        actions.append(curr_sample[\"actions\"][:])\n",
    "        actions_np = np.array(actions)\n",
    "        print(curr_sample[\"actions\"])\n",
    "        # print(actions_np.shape)\n",
    "        dones.append(curr_sample[\"dones\"][:])\n",
    "        obs_keys = curr_sample[\"obs\"].keys()\n",
    "        # print(obs_keys)\n",
    "        # obs_agentviews = curr_sample[\"obs\"][\"agentview_rgb\"]\n",
    "        # print(obs_agentviews)\n",
    "        # obs_eeori = curr_sample[\"obs\"][\"ee_ori\"]\n",
    "        # print(obs_eeori)\n",
    "        # print(curr_sample[\"obs\"][\"ee_states\"])\n",
    "        # for key in obs_keys:\n",
    "            # print(curr_sample[\"obs\"][key])\n",
    "        # for obk in obs_keys:\n",
    "        #     print(obk)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 7)\n",
      "torch.Size([21, 7])\n",
      "torch.Size([21, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "encoder_input_layer = nn.Linear(7, 128)\n",
    "array = np.random.rand(21, 7)\n",
    "print(array.shape)\n",
    "\n",
    "tensor_input = torch.tensor(array, dtype=torch.float32)  # Specify dtype\n",
    "print(tensor_input.shape)\n",
    "\n",
    "# Pass the tensor to the linear layer\n",
    "result = encoder_input_layer(tensor_input)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rgb', 'depth', 'scan', 'low_dim'])\n"
     ]
    }
   ],
   "source": [
    "from robomimic.utils.obs_utils import OBS_MODALITY_CLASSES\n",
    "\n",
    "print(OBS_MODALITY_CLASSES.keys())  # List all recognized observation modalities\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
