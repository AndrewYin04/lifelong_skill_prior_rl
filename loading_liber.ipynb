{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['data']>\n",
      "<KeysViewHDF5 ['demo_0', 'demo_1', 'demo_10', 'demo_11', 'demo_12', 'demo_13', 'demo_14', 'demo_15', 'demo_16', 'demo_17', 'demo_18', 'demo_19', 'demo_2', 'demo_20', 'demo_21', 'demo_22', 'demo_23', 'demo_24', 'demo_25', 'demo_26', 'demo_27', 'demo_28', 'demo_29', 'demo_3', 'demo_30', 'demo_31', 'demo_32', 'demo_33', 'demo_34', 'demo_35', 'demo_36', 'demo_37', 'demo_38', 'demo_39', 'demo_4', 'demo_40', 'demo_41', 'demo_42', 'demo_43', 'demo_44', 'demo_45', 'demo_46', 'demo_47', 'demo_48', 'demo_49', 'demo_5', 'demo_6', 'demo_7', 'demo_8', 'demo_9']>\n",
      "demo_0\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (134, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (134, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (134, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (134, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (134, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (134, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (134, 7), type \"<f8\">\n",
      "demo_1\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (141, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (141, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (141, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (141, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (141, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (141, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (141, 7), type \"<f8\">\n",
      "demo_10\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (140, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (140, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (140, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (140, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (140, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (140, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (140, 7), type \"<f8\">\n",
      "demo_11\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (133, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (133, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (133, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (133, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (133, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (133, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (133, 7), type \"<f8\">\n",
      "demo_12\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (141, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (141, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (141, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (141, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (141, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (141, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (141, 7), type \"<f8\">\n",
      "demo_13\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (124, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (124, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (124, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (124, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (124, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (124, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (124, 7), type \"<f8\">\n",
      "demo_14\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (169, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (169, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (169, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (169, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (169, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (169, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (169, 7), type \"<f8\">\n",
      "demo_15\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (135, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (135, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (135, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (135, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (135, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (135, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (135, 7), type \"<f8\">\n",
      "demo_16\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (143, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (143, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (143, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (143, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (143, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (143, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (143, 7), type \"<f8\">\n",
      "demo_17\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (140, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (140, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (140, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (140, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (140, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (140, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (140, 7), type \"<f8\">\n",
      "demo_18\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (142, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (142, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (142, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (142, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (142, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (142, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (142, 7), type \"<f8\">\n",
      "demo_19\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (145, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (145, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (145, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (145, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (145, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (145, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (145, 7), type \"<f8\">\n",
      "demo_2\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (129, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (129, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (129, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (129, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (129, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (129, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (129, 7), type \"<f8\">\n",
      "demo_20\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (126, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (126, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (126, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (126, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (126, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (126, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (126, 7), type \"<f8\">\n",
      "demo_21\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (132, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (132, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (132, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (132, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (132, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (132, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (132, 7), type \"<f8\">\n",
      "demo_22\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (136, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (136, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (136, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (136, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (136, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (136, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (136, 7), type \"<f8\">\n",
      "demo_23\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (136, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (136, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (136, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (136, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (136, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (136, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (136, 7), type \"<f8\">\n",
      "demo_24\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (146, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (146, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (146, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (146, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (146, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (146, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (146, 7), type \"<f8\">\n",
      "demo_25\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (136, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (136, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (136, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (136, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (136, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (136, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (136, 7), type \"<f8\">\n",
      "demo_26\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (131, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (131, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (131, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (131, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (131, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (131, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (131, 7), type \"<f8\">\n",
      "demo_27\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (108, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (108, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (108, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (108, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (108, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (108, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (108, 7), type \"<f8\">\n",
      "demo_28\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (139, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (139, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (139, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (139, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (139, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (139, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (139, 7), type \"<f8\">\n",
      "demo_29\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (144, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (144, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (144, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (144, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (144, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (144, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (144, 7), type \"<f8\">\n",
      "demo_3\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (120, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (120, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (120, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (120, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (120, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (120, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (120, 7), type \"<f8\">\n",
      "demo_30\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (140, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (140, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (140, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (140, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (140, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (140, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (140, 7), type \"<f8\">\n",
      "demo_31\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (122, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (122, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (122, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (122, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (122, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (122, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (122, 7), type \"<f8\">\n",
      "demo_32\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (131, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (131, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (131, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (131, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (131, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (131, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (131, 7), type \"<f8\">\n",
      "demo_33\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (166, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (166, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (166, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (166, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (166, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (166, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (166, 7), type \"<f8\">\n",
      "demo_34\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (115, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (115, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (115, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (115, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (115, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (115, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (115, 7), type \"<f8\">\n",
      "demo_35\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (134, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (134, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (134, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (134, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (134, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (134, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (134, 7), type \"<f8\">\n",
      "demo_36\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (172, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (172, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (172, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (172, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (172, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (172, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (172, 7), type \"<f8\">\n",
      "demo_37\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (141, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (141, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (141, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (141, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (141, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (141, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (141, 7), type \"<f8\">\n",
      "demo_38\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (130, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (130, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (130, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (130, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (130, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (130, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (130, 7), type \"<f8\">\n",
      "demo_39\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (144, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (144, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (144, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (144, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (144, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (144, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (144, 7), type \"<f8\">\n",
      "demo_4\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (142, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (142, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (142, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (142, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (142, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (142, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (142, 7), type \"<f8\">\n",
      "demo_40\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (134, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (134, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (134, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (134, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (134, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (134, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (134, 7), type \"<f8\">\n",
      "demo_41\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (139, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (139, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (139, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (139, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (139, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (139, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (139, 7), type \"<f8\">\n",
      "demo_42\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (144, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (144, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (144, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (144, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (144, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (144, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (144, 7), type \"<f8\">\n",
      "demo_43\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (133, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (133, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (133, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (133, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (133, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (133, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (133, 7), type \"<f8\">\n",
      "demo_44\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (127, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (127, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (127, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (127, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (127, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (127, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (127, 7), type \"<f8\">\n",
      "demo_45\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (125, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (125, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (125, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (125, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (125, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (125, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (125, 7), type \"<f8\">\n",
      "demo_46\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (149, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (149, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (149, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (149, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (149, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (149, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (149, 7), type \"<f8\">\n",
      "demo_47\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (126, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (126, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (126, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (126, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (126, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (126, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (126, 7), type \"<f8\">\n",
      "demo_48\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (175, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (175, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (175, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (175, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (175, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (175, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (175, 7), type \"<f8\">\n",
      "demo_49\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (132, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (132, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (132, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (132, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (132, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (132, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (132, 7), type \"<f8\">\n",
      "demo_5\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (138, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (138, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (138, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (138, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (138, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (138, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (138, 7), type \"<f8\">\n",
      "demo_6\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (120, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (120, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (120, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (120, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (120, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (120, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (120, 7), type \"<f8\">\n",
      "demo_7\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (123, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (123, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (123, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (123, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (123, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (123, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (123, 7), type \"<f8\">\n",
      "demo_8\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (142, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (142, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (142, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (142, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (142, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (142, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (142, 7), type \"<f8\">\n",
      "demo_9\n",
      "<KeysViewHDF5 ['agentview_rgb', 'ee_ori', 'ee_pos', 'ee_states', 'eye_in_hand_rgb', 'gripper_states', 'joint_states']>\n",
      "<HDF5 dataset \"agentview_rgb\": shape (196, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"ee_ori\": shape (196, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_pos\": shape (196, 3), type \"<f8\">\n",
      "<HDF5 dataset \"ee_states\": shape (196, 6), type \"<f8\">\n",
      "<HDF5 dataset \"eye_in_hand_rgb\": shape (196, 128, 128, 3), type \"|u1\">\n",
      "<HDF5 dataset \"gripper_states\": shape (196, 2), type \"<f8\">\n",
      "<HDF5 dataset \"joint_states\": shape (196, 7), type \"<f8\">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53769/1535777110.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  actions_np = np.array(actions)\n"
     ]
    }
   ],
   "source": [
    "actions = []\n",
    "dones = []\n",
    "obs = []\n",
    "rewards = []\n",
    "robot_states = []\n",
    "states = []\n",
    "\n",
    "with h5py.File(\"/home/fri-skills/LIBERO/libero/datasets/libero_90/KITCHEN_SCENE2_put_the_black_bowl_at_the_front_on_the_plate_demo.hdf5\", \"r\") as file:\n",
    "    data_group = file['data']\n",
    "    print(file.keys())\n",
    "    print(data_group.keys())\n",
    "    for sample in data_group.keys():\n",
    "        print(sample)\n",
    "        curr_sample = data_group[sample]\n",
    "        # print(curr_sample.keys())\n",
    "        curr_sample[\"actions\"][:]\n",
    "        actions.append(curr_sample[\"actions\"][:])\n",
    "        actions_np = np.array(actions)\n",
    "        # print(curr_sample[\"actions\"])\n",
    "        # print(actions_np.shape)\n",
    "        dones.append(curr_sample[\"dones\"][:])\n",
    "        obs_keys = curr_sample[\"obs\"].keys()\n",
    "        print(obs_keys)\n",
    "        \n",
    "        # print(obs_keys)\n",
    "        # obs_agentviews = curr_sample[\"obs\"][\"agentview_rgb\"]\n",
    "        # print(obs_agentviews)\n",
    "        # obs_eeori = curr_sample[\"obs\"][\"ee_ori\"]\n",
    "        # print(obs_eeori)\n",
    "        # print(curr_sample[\"obs\"][\"ee_states\"])\n",
    "        for key in obs_keys:\n",
    "            print(curr_sample[\"obs\"][key])\n",
    "        # for obk in obs_keys:\n",
    "        #     print(obk)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 22, 7)\n",
      "torch.Size([21, 22, 7])\n",
      "torch.Size([21, 22, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "encoder_input_layer = nn.Linear(7, 128)\n",
    "array = np.random.rand(21, 22, 7)\n",
    "print(array.shape)\n",
    "\n",
    "tensor_input = torch.tensor(array, dtype=torch.float32)  # Specify dtype\n",
    "print(tensor_input.shape)\n",
    "\n",
    "# Pass the tensor to the linear layer\n",
    "result = encoder_input_layer(tensor_input)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rgb', 'depth', 'scan', 'low_dim'])\n"
     ]
    }
   ],
   "source": [
    "from robomimic.utils.obs_utils import OBS_MODALITY_CLASSES\n",
    "\n",
    "print(OBS_MODALITY_CLASSES.keys())  # List all recognized observation modalities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "/home/fri-skills/LIBERO/libero/libero/./bddl_files/libero_10/LIVING_ROOM_SCENE2_put_both_the_alphabet_soup_and_the_tomato_sauce_in_the_basket.bddl\n",
      "[info] retrieving task 0 from suite libero_10, the language instruction is put both the alphabet soup and the tomato sauce in the basket, and the bddl file is /home/fri-skills/LIBERO/libero/libero/./bddl_files/libero_10/LIVING_ROOM_SCENE2_put_both_the_alphabet_soup_and_the_tomato_sauce_in_the_basket.bddl\n",
      "odict_keys(['robot0_joint_pos', 'robot0_joint_pos_cos', 'robot0_joint_pos_sin', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'agentview_image', 'robot0_eye_in_hand_image', 'alphabet_soup_1_pos', 'alphabet_soup_1_quat', 'alphabet_soup_1_to_robot0_eef_pos', 'alphabet_soup_1_to_robot0_eef_quat', 'cream_cheese_1_pos', 'cream_cheese_1_quat', 'cream_cheese_1_to_robot0_eef_pos', 'cream_cheese_1_to_robot0_eef_quat', 'tomato_sauce_1_pos', 'tomato_sauce_1_quat', 'tomato_sauce_1_to_robot0_eef_pos', 'tomato_sauce_1_to_robot0_eef_quat', 'ketchup_1_pos', 'ketchup_1_quat', 'ketchup_1_to_robot0_eef_pos', 'ketchup_1_to_robot0_eef_quat', 'orange_juice_1_pos', 'orange_juice_1_quat', 'orange_juice_1_to_robot0_eef_pos', 'orange_juice_1_to_robot0_eef_quat', 'milk_1_pos', 'milk_1_quat', 'milk_1_to_robot0_eef_pos', 'milk_1_to_robot0_eef_quat', 'butter_1_pos', 'butter_1_quat', 'butter_1_to_robot0_eef_pos', 'butter_1_to_robot0_eef_quat', 'basket_1_pos', 'basket_1_quat', 'basket_1_to_robot0_eef_pos', 'basket_1_to_robot0_eef_quat', 'robot0_proprio-state', 'object-state'])\n",
      "odict_keys(['robot0_joint_pos', 'robot0_joint_pos_cos', 'robot0_joint_pos_sin', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'agentview_image', 'robot0_eye_in_hand_image', 'alphabet_soup_1_pos', 'alphabet_soup_1_quat', 'alphabet_soup_1_to_robot0_eef_pos', 'alphabet_soup_1_to_robot0_eef_quat', 'cream_cheese_1_pos', 'cream_cheese_1_quat', 'cream_cheese_1_to_robot0_eef_pos', 'cream_cheese_1_to_robot0_eef_quat', 'tomato_sauce_1_pos', 'tomato_sauce_1_quat', 'tomato_sauce_1_to_robot0_eef_pos', 'tomato_sauce_1_to_robot0_eef_quat', 'ketchup_1_pos', 'ketchup_1_quat', 'ketchup_1_to_robot0_eef_pos', 'ketchup_1_to_robot0_eef_quat', 'orange_juice_1_pos', 'orange_juice_1_quat', 'orange_juice_1_to_robot0_eef_pos', 'orange_juice_1_to_robot0_eef_quat', 'milk_1_pos', 'milk_1_quat', 'milk_1_to_robot0_eef_pos', 'milk_1_to_robot0_eef_quat', 'butter_1_pos', 'butter_1_quat', 'butter_1_to_robot0_eef_pos', 'butter_1_to_robot0_eef_quat', 'basket_1_pos', 'basket_1_quat', 'basket_1_to_robot0_eef_pos', 'basket_1_to_robot0_eef_quat', 'robot0_proprio-state', 'object-state'])\n"
     ]
    }
   ],
   "source": [
    "from Models.PolicyNetwork import PolicyNetwork\n",
    "from Models.CriticNetwork import CriticNetwork\n",
    "from Models.ReplayBuffer import ReplayBuffer\n",
    "from Models.SkillEmbeddingPrior import SkillEmbeddingAndPrior\n",
    "from Models.SkillPriorNet import SkillPriorNet\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from libero.lifelong.datasets import get_dataset\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.kl import kl_divergence\n",
    "from colorama import Fore, Style\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gym\n",
    "from libero.libero import benchmark\n",
    "from libero.libero.envs import OffScreenRenderEnv\n",
    "import os\n",
    "from libero_env import make_env, CFG\n",
    "\n",
    "\n",
    "from libero.libero import benchmark, get_libero_path\n",
    "from libero.libero.envs import OffScreenRenderEnv\n",
    "\n",
    "use_arnav_code = False\n",
    "if use_arnav_code:\n",
    "    env = make_env(CFG(\"libero_object\", 0, \"rgb\"))\n",
    "else:\n",
    "    benchmark_dict = benchmark.get_benchmark_dict()\n",
    "    task_suite_name = \"libero_10\" # can also choose libero_spatial, libero_object, etc.\n",
    "    task_suite = benchmark_dict[task_suite_name]()\n",
    "\n",
    "    # retrieve a specific task\n",
    "    task_id = 0\n",
    "    task = task_suite.get_task(task_id)\n",
    "    task_name = task.name\n",
    "    task_description = task.language\n",
    "    task_bddl_file = os.path.join(get_libero_path(\"bddl_files\"), task.problem_folder, task.bddl_file)\n",
    "    print(task_bddl_file)\n",
    "    print(f\"[info] retrieving task {task_id} from suite {task_suite_name}, the \" + \\\n",
    "        f\"language instruction is {task_description}, and the bddl file is {task_bddl_file}\")\n",
    "\n",
    "    # step over the environment\n",
    "    env_args = {\n",
    "        \"bddl_file_name\": task_bddl_file,\n",
    "        \"camera_heights\": 128,\n",
    "        \"camera_widths\": 128\n",
    "    }\n",
    "    env = OffScreenRenderEnv(**env_args)\n",
    "\n",
    "    print(env.env.observation_spec().keys())\n",
    "    env.seed(0)\n",
    "    env.reset()\n",
    "    init_states = task_suite.get_task_init_states(task_id) # for benchmarking purpose, we fix the a set of initial states\n",
    "    init_state_id = 0\n",
    "    env.set_init_state(init_states[init_state_id])\n",
    "    # print(init_states[0].shape);quit()\n",
    "    dummy_action = [0.] * 7\n",
    "\n",
    "\"\"\"\n",
    "doesnt work b/c observation() never gets called\n",
    "class FlattenObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env: gym.Env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = spaces.flatten_space(env.env.observation_spec())\n",
    "        self.state_dim = len(self.observation_space)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # return spaces.flatten(self.env.env.observation_spec(), observation)\n",
    "        state_size = 0\n",
    "        state_dim = 0\n",
    "        state_col_arr = []\n",
    "        for entry in list(observation.values()):\n",
    "            # state_size += 1\n",
    "            try:\n",
    "                for entry2 in entry:\n",
    "                    try:\n",
    "                        for entry3 in entry2:\n",
    "                            state_size += 1\n",
    "                            state_col_arr.append(entry3)\n",
    "                    except:\n",
    "                        state_size += 1\n",
    "                        state_col_arr.append(entry2)\n",
    "            except:\n",
    "                state_size += 1\n",
    "                state_col_arr.append(entry)\n",
    "            # state_dim = state_size\n",
    "            # print(state_size)\n",
    "            # state_size = 0\n",
    "        state_dim = state_size\n",
    "        raise ''\n",
    "        print('START',np.array(state_col_arr),'END');quit()\n",
    "        return np.array(state_col_arr)\n",
    "\"\"\"\n",
    "# env.observation_space OrderedDict space\n",
    "# from gym.wrappers import FlattenObservation\n",
    "# env = FlattenObservation(env)\n",
    "# Box\n",
    "for step in range(10):\n",
    "    # obs OrderedDict\n",
    "    obs, reward, done, info = env.step(dummy_action)\n",
    "    print(obs.keys())\n",
    "    break\n",
    "    # obs vector\n",
    "    # print(len(list(obs.values())));quit()\n",
    "\n",
    "# state_dim = env.observation_space.shape[0]\n",
    "# action_dim = list(env.env.action_spec)[0].shape[0]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
